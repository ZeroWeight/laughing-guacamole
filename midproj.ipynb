{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing with Disaster Tweets\n",
    "## Weitong Zhang, UID: 705302329, Email: <weightzero@g.ucla.edu>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pickle\n",
    "from clean import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Here we read the data and preprocess it, we use the data preprocessing method provided by [DisaterTweets](https://www.kaggle.com/zinebkhanjari/disastertweets#Preprocessing) to clean up the non-text, emojis, and abbreviations.\n",
    "We move the copied code into `clean.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>NUMBER people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1  our deeds are the reason of this #earthquake m...  \n",
       "1       1            forest fire near la ronge sask. canada   \n",
       "2       1  all residents asked to 'shelter in place' are ...  \n",
       "3       1  NUMBER people receive #wildfires evacuation or...  \n",
       "4       1  just got sent this photo from ruby #alaska as ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "def clean_tweet(text):\n",
    "    # Remove non text\n",
    "    text = remove_URL(text)\n",
    "    text = remove_HTML(text)\n",
    "    text = remove_not_ASCII(text)\n",
    "    \n",
    "    # Lower text, replace abbreviations\n",
    "    text = text.lower()\n",
    "    text = replace_abbrev(text)  \n",
    "    text = remove_mention(text)\n",
    "    text = remove_number(text)\n",
    "    \n",
    "    # Remove emojis / smileys\n",
    "    text = remove_emoji(text)\n",
    "    text = transcription_sad(text)\n",
    "    text = transcription_smile(text)\n",
    "    text = transcription_heart(text)\n",
    "    \n",
    "    # Remove repeated punctuation / words\n",
    "    text = remove_elongated_words(text)\n",
    "    text = remove_repeat_punct(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "train[\"clean_text\"] = train[\"text\"].apply(clean_tweet)\n",
    "test[\"clean_text\"] = test[\"text\"].apply(clean_tweet)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline\n",
    "\n",
    "Next we are about to propose several vectorization method and training model.\n",
    "But before that, we are about to introduce the training pipeline to integrate\n",
    "all training method later, which includes the following five parts in general.\n",
    "\n",
    "vectorization --> train-text split -->  training --> evaluation --> test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(Vectorizer, Trainer):\n",
    "    y = train.target\n",
    "    trainX, valX, trainY, valY = train_test_split(Vectorizer.trainX, y, test_size = 0.3)\n",
    "    Trainer.train(trainX, trainY)\n",
    "    predTrain = Trainer.predict(trainX)\n",
    "    predVal = Trainer.predict(valX)\n",
    "    print('\\t{} + {}:'.format(str(Vectorizer), str(Trainer)))\n",
    "    print('-' * 60)\n",
    "    print('Training Dataset')\n",
    "    print(classification_report(trainY, predTrain))\n",
    "    print('-' * 60)\n",
    "    print('Validation Dataset')\n",
    "    print(classification_report(valY, predVal))\n",
    "    print('=' * 60)\n",
    "    trainX, trainY = Vectorizer.trainX, y\n",
    "    Trainer.train(trainX, trainY)\n",
    "    test['target'] = Trainer.predict(Vectorizer.testX)\n",
    "    test[['id', 'target']].to_csv('./output/{}_{}.csv'.format(str(Vectorizer), str(Trainer)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "#### Count Vectorizer and TF-IDF Vectorizer (scikit-learn provided)\n",
    "\n",
    "The first two vectorization methods are the Count Vectorizer and TF-IDF vectorizer\n",
    "provided by scikit-learn. Count vectorizer which simply counts the time of \n",
    "appearance of each word in the sentence. TF-IDF vectorizer maintain another count\n",
    "mectric which weight more on the 'unusual' words. These two vectorizers are simple\n",
    "but might ignore the combination of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sklearnVectorizer:\n",
    "    def __init__(self, obj):\n",
    "        self.obj = obj\n",
    "        self.vec = obj()\n",
    "        self.trainX = self.vec.fit_transform(train['clean_text'])\n",
    "        self.testX = self.vec.transform(test['clean_text'])\n",
    "    def __str__(self):\n",
    "        return str(self.obj.__name__)\n",
    "skvector = [CountVectorizer, TfidfVectorizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT pretrained feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bertVectorizer:\n",
    "    def __init__(self, rebuild=False, model_id='bert-base-uncased'):\n",
    "        self.model_id = model_id\n",
    "        model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, model_id)\n",
    "        tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "        model = model_class.from_pretrained(pretrained_weights)\n",
    "        if not rebuild:\n",
    "            with open('./data/' + model_id + '_feature.pkl', 'rb') as f:\n",
    "                D = pickle.load(f)\n",
    "                self.trainX = D['train']\n",
    "                self.testX = D['test']\n",
    "            return\n",
    "        T = tokenizer.batch_encode_plus(train.text.apply(preprocess), max_length=64, add_special_tokens=True, return_attention_mask=True,padding=True,truncation=True)\n",
    "        input_id = torch.tensor(T['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(T['attention_mask'], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            X = model(input_id, attention_mask=mask)[0][:,0,:]\n",
    "        self.trainX = X.numpy()\n",
    "        T = tokenizer.batch_encode_plus(test.text.apply(preprocess), max_length=64, add_special_tokens=True, return_attention_mask=True,padding=True,truncation=True)\n",
    "        input_id = torch.tensor(T['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(T['attention_mask'], dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            X = model(input_id, attention_mask=mask)[0][:,0,:]\n",
    "        self.testX = X.numpy()\n",
    "        with open('./data/' + model_id + '_feature.pkl', 'wb') as f:\n",
    "            pickle.dump({'train': self.trainX, 'test': self.testX}, f)\n",
    "    def __str__(self):\n",
    "        return self.model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "We are using the scikit-learn provided learner such as Losistic Regression, SVC, Decision Tree, Random Forest and kNN. Fine-tuning model is discussed in the report but we will skip it due to its heavy computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sklearnTrainer:\n",
    "    def __init__(self, obj):\n",
    "        self.obj = obj\n",
    "    def train(self, X, y):\n",
    "        self.clf = self.obj().fit(X, y)\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    def __str__(self):\n",
    "        return str(self.obj.__name__)\n",
    "sklearner = [LogisticRegression, SVC, DecisionTreeClassifier, KNeighborsClassifier, RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Here we first show the result using scikit-learn provided methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\tCountVectorizer + LogisticRegression:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3025\n",
      "           1       0.98      0.92      0.95      2304\n",
      "\n",
      "    accuracy                           0.96      5329\n",
      "   macro avg       0.96      0.95      0.96      5329\n",
      "weighted avg       0.96      0.96      0.96      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      1317\n",
      "           1       0.79      0.67      0.73       967\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.79      0.77      0.77      2284\n",
      "weighted avg       0.79      0.79      0.78      2284\n",
      "\n",
      "============================================================\n",
      "\tCountVectorizer + SVC:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      3063\n",
      "           1       0.98      0.87      0.92      2266\n",
      "\n",
      "    accuracy                           0.94      5329\n",
      "   macro avg       0.95      0.93      0.94      5329\n",
      "weighted avg       0.94      0.94      0.94      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      1279\n",
      "           1       0.85      0.62      0.72      1005\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.80      0.77      0.77      2284\n",
      "weighted avg       0.80      0.78      0.78      2284\n",
      "\n",
      "============================================================\n",
      "\tCountVectorizer + DecisionTreeClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3036\n",
      "           1       1.00      0.98      0.99      2293\n",
      "\n",
      "    accuracy                           0.99      5329\n",
      "   macro avg       0.99      0.99      0.99      5329\n",
      "weighted avg       0.99      0.99      0.99      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1306\n",
      "           1       0.69      0.65      0.67       978\n",
      "\n",
      "    accuracy                           0.72      2284\n",
      "   macro avg       0.72      0.71      0.72      2284\n",
      "weighted avg       0.72      0.72      0.72      2284\n",
      "\n",
      "============================================================\n",
      "\tCountVectorizer + KNeighborsClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82      3036\n",
      "           1       0.92      0.47      0.63      2293\n",
      "\n",
      "    accuracy                           0.76      5329\n",
      "   macro avg       0.82      0.72      0.72      5329\n",
      "weighted avg       0.80      0.76      0.74      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78      1306\n",
      "           1       0.85      0.36      0.50       978\n",
      "\n",
      "    accuracy                           0.70      2284\n",
      "   macro avg       0.76      0.65      0.64      2284\n",
      "weighted avg       0.74      0.70      0.66      2284\n",
      "\n",
      "============================================================\n",
      "\tCountVectorizer + RandomForestClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3029\n",
      "           1       1.00      0.98      0.99      2300\n",
      "\n",
      "    accuracy                           0.99      5329\n",
      "   macro avg       0.99      0.99      0.99      5329\n",
      "weighted avg       0.99      0.99      0.99      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83      1313\n",
      "           1       0.85      0.60      0.70       971\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.80      0.76      0.77      2284\n",
      "weighted avg       0.79      0.78      0.78      2284\n",
      "\n",
      "============================================================\n",
      "\tTfidfVectorizer + LogisticRegression:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      2995\n",
      "           1       0.95      0.80      0.87      2334\n",
      "\n",
      "    accuracy                           0.89      5329\n",
      "   macro avg       0.90      0.88      0.89      5329\n",
      "weighted avg       0.90      0.89      0.89      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      1347\n",
      "           1       0.81      0.64      0.71       937\n",
      "\n",
      "    accuracy                           0.79      2284\n",
      "   macro avg       0.79      0.77      0.77      2284\n",
      "weighted avg       0.79      0.79      0.78      2284\n",
      "\n",
      "============================================================\n",
      "\tTfidfVectorizer + SVC:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3050\n",
      "           1       0.99      0.93      0.96      2279\n",
      "\n",
      "    accuracy                           0.97      5329\n",
      "   macro avg       0.97      0.96      0.96      5329\n",
      "weighted avg       0.97      0.97      0.97      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84      1292\n",
      "           1       0.89      0.61      0.72       992\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.83      0.78      0.78      2284\n",
      "weighted avg       0.82      0.80      0.79      2284\n",
      "\n",
      "============================================================\n",
      "\tTfidfVectorizer + DecisionTreeClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3033\n",
      "           1       1.00      0.98      0.99      2296\n",
      "\n",
      "    accuracy                           0.99      5329\n",
      "   macro avg       0.99      0.99      0.99      5329\n",
      "weighted avg       0.99      0.99      0.99      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      1309\n",
      "           1       0.67      0.60      0.63       975\n",
      "\n",
      "    accuracy                           0.70      2284\n",
      "   macro avg       0.70      0.69      0.69      2284\n",
      "weighted avg       0.70      0.70      0.70      2284\n",
      "\n",
      "============================================================\n",
      "\tTfidfVectorizer + KNeighborsClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      3017\n",
      "           1       0.86      0.74      0.80      2312\n",
      "\n",
      "    accuracy                           0.84      5329\n",
      "   macro avg       0.84      0.82      0.83      5329\n",
      "weighted avg       0.84      0.84      0.83      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      1325\n",
      "           1       0.77      0.66      0.71       959\n",
      "\n",
      "    accuracy                           0.77      2284\n",
      "   macro avg       0.77      0.76      0.76      2284\n",
      "weighted avg       0.77      0.77      0.77      2284\n",
      "\n",
      "============================================================\n",
      "\tTfidfVectorizer + RandomForestClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3046\n",
      "           1       0.99      0.98      0.99      2283\n",
      "\n",
      "    accuracy                           0.99      5329\n",
      "   macro avg       0.99      0.99      0.99      5329\n",
      "weighted avg       0.99      0.99      0.99      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83      1296\n",
      "           1       0.88      0.58      0.70       988\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.81      0.76      0.76      2284\n",
      "weighted avg       0.80      0.78      0.77      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-base-uncased + LogisticRegression:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      3024\n",
      "           1       0.86      0.79      0.82      2305\n",
      "\n",
      "    accuracy                           0.85      5329\n",
      "   macro avg       0.85      0.84      0.85      5329\n",
      "weighted avg       0.85      0.85      0.85      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81      1318\n",
      "           1       0.76      0.70      0.73       966\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.78      0.77      0.77      2284\n",
      "weighted avg       0.78      0.78      0.78      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-base-uncased + SVC:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      3038\n",
      "           1       0.89      0.69      0.78      2291\n",
      "\n",
      "    accuracy                           0.83      5329\n",
      "   macro avg       0.85      0.81      0.82      5329\n",
      "weighted avg       0.84      0.83      0.83      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84      1304\n",
      "           1       0.83      0.67      0.75       980\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.81      0.79      0.79      2284\n",
      "weighted avg       0.81      0.80      0.80      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-base-uncased + DecisionTreeClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3055\n",
      "           1       1.00      0.96      0.98      2274\n",
      "\n",
      "    accuracy                           0.98      5329\n",
      "   macro avg       0.98      0.98      0.98      5329\n",
      "weighted avg       0.98      0.98      0.98      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72      1287\n",
      "           1       0.63      0.60      0.62       997\n",
      "\n",
      "    accuracy                           0.67      2284\n",
      "   macro avg       0.67      0.67      0.67      2284\n",
      "weighted avg       0.67      0.67      0.67      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-base-uncased + KNeighborsClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      3041\n",
      "           1       0.86      0.73      0.79      2288\n",
      "\n",
      "    accuracy                           0.83      5329\n",
      "   macro avg       0.84      0.82      0.82      5329\n",
      "weighted avg       0.84      0.83      0.83      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      1301\n",
      "           1       0.77      0.64      0.70       983\n",
      "\n",
      "    accuracy                           0.76      2284\n",
      "   macro avg       0.77      0.75      0.75      2284\n",
      "weighted avg       0.77      0.76      0.76      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-base-uncased + RandomForestClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3078\n",
      "           1       0.98      0.98      0.98      2251\n",
      "\n",
      "    accuracy                           0.98      5329\n",
      "   macro avg       0.98      0.98      0.98      5329\n",
      "weighted avg       0.98      0.98      0.98      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.82      1264\n",
      "           1       0.83      0.63      0.72      1020\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.79      0.76      0.77      2284\n",
      "weighted avg       0.78      0.78      0.77      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-large-uncased + LogisticRegression:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      3047\n",
      "           1       0.88      0.81      0.85      2282\n",
      "\n",
      "    accuracy                           0.87      5329\n",
      "   macro avg       0.87      0.87      0.87      5329\n",
      "weighted avg       0.87      0.87      0.87      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      1295\n",
      "           1       0.74      0.69      0.72       989\n",
      "\n",
      "    accuracy                           0.76      2284\n",
      "   macro avg       0.76      0.75      0.76      2284\n",
      "weighted avg       0.76      0.76      0.76      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-large-uncased + SVC:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87      3017\n",
      "           1       0.89      0.72      0.79      2312\n",
      "\n",
      "    accuracy                           0.84      5329\n",
      "   macro avg       0.85      0.82      0.83      5329\n",
      "weighted avg       0.84      0.84      0.84      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1325\n",
      "           1       0.83      0.69      0.76       959\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.82      0.80      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-large-uncased + DecisionTreeClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3047\n",
      "           1       1.00      0.96      0.98      2282\n",
      "\n",
      "    accuracy                           0.98      5329\n",
      "   macro avg       0.98      0.98      0.98      5329\n",
      "weighted avg       0.98      0.98      0.98      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.72      0.73      1295\n",
      "           1       0.64      0.64      0.64       989\n",
      "\n",
      "    accuracy                           0.69      2284\n",
      "   macro avg       0.68      0.68      0.68      2284\n",
      "weighted avg       0.69      0.69      0.69      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-large-uncased + KNeighborsClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      3014\n",
      "           1       0.81      0.80      0.80      2315\n",
      "\n",
      "    accuracy                           0.83      5329\n",
      "   macro avg       0.83      0.83      0.83      5329\n",
      "weighted avg       0.83      0.83      0.83      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1328\n",
      "           1       0.70      0.72      0.71       956\n",
      "\n",
      "    accuracy                           0.75      2284\n",
      "   macro avg       0.75      0.75      0.75      2284\n",
      "weighted avg       0.75      0.75      0.75      2284\n",
      "\n",
      "============================================================\n",
      "\tbert-large-uncased + RandomForestClassifier:\n",
      "------------------------------------------------------------\n",
      "Training Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3077\n",
      "           1       0.99      0.97      0.98      2252\n",
      "\n",
      "    accuracy                           0.98      5329\n",
      "   macro avg       0.98      0.98      0.98      5329\n",
      "weighted avg       0.98      0.98      0.98      5329\n",
      "\n",
      "------------------------------------------------------------\n",
      "Validation Dataset\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.82      1265\n",
      "           1       0.86      0.62      0.72      1019\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.80      0.77      0.77      2284\n",
      "weighted avg       0.80      0.78      0.78      2284\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('=' * 60)\n",
    "for v in skvector:\n",
    "    for l in sklearner:\n",
    "        run(sklearnVectorizer(v), sklearnTrainer(l))\n",
    "for v in ['bert-base-uncased', 'bert-large-uncased']:\n",
    "    for l in sklearner:\n",
    "        run(bertVectorizer(model_id=v), sklearnTrainer(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs263",
   "language": "python",
   "name": "cs263"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
